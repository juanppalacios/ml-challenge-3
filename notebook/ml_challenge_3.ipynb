{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS 678 - Machine Learning - Kaggle Challenge 3: MNIST Digit Classification\n",
    "\n",
    "<!-- ## Data Loading -->\n",
    "\n",
    "<!-- ## Model Implementation -->\n",
    "\n",
    "<!-- ## Model Evaluation -->\n",
    "\n",
    "<!-- ## Conclusion -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Configuration\n",
    "Before running our model, let's change our working directory over to our Python scripts by running the following shell script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!echo sourcing MNIST model directory...\n",
    "%cd '../model/src/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing our Custom Neural Network Libraries\n",
    "Now that were are under the right directory, let's start off by importing all of our custom Python scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# custom modules\n",
    "from toolkit import Toolkit\n",
    "from parameters import ParameterManager\n",
    "from model import Model\n",
    "\n",
    "# used for visualizing our training progress\n",
    "from rich.progress import track\n",
    "\n",
    "# import cross validation libraries\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# creating our notebook toolkit helper\n",
    "tools = Toolkit()\n",
    "tools.configure(name = 'Notebook', level = 'INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Configuration\n",
    "Parameter selection is model development makes it easier to optimize our model.\n",
    "For example, if we can tune our model's learning rate value and see its effects on model performance.\n",
    "Using our custom `ParameterManager` class, we can easily create a variety of parameters to pass onto our MNIST model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter manager\n",
    "parameters = ParameterManager()\n",
    "\n",
    "# create learning parameters\n",
    "parameters.add_parameter(epochs = [15])\n",
    "parameters.add_parameter(learning_rate = [0.001]) # note: 0.1 too high, 0.0001 to low?\n",
    "parameters.add_parameter(loss = ['mse'])\n",
    "parameters.add_parameter(select_case = [-1])\n",
    "\n",
    "# create an architecture parameter\n",
    "parameters.add_nested_parameter(hidden_layers = [2], hidden_dimensions = [256, 128, 64], activation = ['tanh'])\n",
    "\n",
    "tools.info(f'showing notebook parameters: {parameters}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Data\n",
    "This model will train on the MNIST data set.\n",
    "A collection of three `csv` files are imported to generate our training and testing data sets.\n",
    "Let's load in our `mnist_train.csv`, `mnist_train_targets.csv`, and `mnist_test.csv` files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.info(\"loading in our MNIST data sets\")\n",
    "\n",
    "train_data    = tools.load_data(\"../data/train/mnist_train.csv\")\n",
    "train_targets = tools.load_data(\"../data/train/mnist_train_targets.csv\", transpose = False)\n",
    "test_data     = tools.load_data(\"../data/test/mnist_test.csv\")\n",
    "test_targets  = np.zeros((test_data.shape[0], 1), dtype=int)\n",
    "\n",
    "tools.info(f\"read in our data with shapes: {train_data.shape} and {train_targets.shape} \")\n",
    "tools.info(f\"read in our data with shapes: {test_data.shape} and {test_targets.shape} \")\n",
    "\n",
    "tools.info(\"applying normalization to our train data\")\n",
    "train_data = tools.normalize(train_data)\n",
    "test_data  = tools.normalize(test_data)\n",
    "\n",
    "tools.info(\"visualizing a few MNIST training samples...\")\n",
    "tools.visualize(train_data)\n",
    "\n",
    "tools.info(\"visualizing a few MNIST testing samples...\")\n",
    "tools.visualize(test_data)\n",
    "\n",
    "tools.warning(\"plots should be labaled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Model Configuration and Compilation\n",
    "With our training and testing data sets ready for processing and all of our tunable parameters declared, we can start compiling our custom neural architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = Model(debug_mode = False)\n",
    "\n",
    "mnist_model.configure(parameters = parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validating Model Performance\n",
    "The following section describes our model performance over all parameter variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine your train and test data and targets\n",
    "X = np.concatenate((train_data, test_data), axis=0)\n",
    "y = np.concatenate((train_targets, test_targets), axis=0)\n",
    "\n",
    "#> performing cross-validation to assess model performance\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "#> run cross-validation train and predict loop\n",
    "for train_index, test_index in kf.split(X):\n",
    "  X_train, X_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "  # Your model training and evaluation here\n",
    "  mnist_model.fit(X_train, y_train)\n",
    "  y_pred = mnist_model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model (use appropriate evaluation metric based on your problem)\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  tools.info(f\"cross-validation accuracy: {accuracy * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Kaggle Submission\n",
    "Now that we have cross-validated our model's performance, we can retrain our model with the full training data set to generate our test targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model.fit(train_data, train_targets)\n",
    "\n",
    "test_targets = mnist_model.predict(test_data)\n",
    "\n",
    "tools.info(\"saving our test targets\")\n",
    "\n",
    "tools.save_data(\"../data/test/mnist_test_targets.csv\", test_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
